{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"goodreads_data.csv\", engine=\"python\", quotechar='\"', on_bad_lines=\"skip\");\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9923, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = df.dropna(axis=0, subset=[\"Author\", \"Description\", \"Genres\", 'Book'])\n",
    "ndf.duplicated(keep='last', subset=[\"Book\"])\n",
    "\n",
    "ndf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "def eliminate_stop_words(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_word = []\n",
    "    for word in word_tokens:\n",
    "        if word not in stop_words:\n",
    "            filtered_word.append(word)\n",
    "\n",
    "    filtered_text = ' '.join(filtered_word)\n",
    "    print(filtered_text)\n",
    "    return filtered_text \n",
    "\n",
    "ndf['cleaned_genres'] = ndf['Genres'].apply(eliminate_stop_words)\n",
    "#ndf['cleaned_combined'] = ndf['cleaned_desc'] + ' ' + ndf['Genres'] + ' ' + ndf['Author']\n",
    "ndf['cleaned_combined'] = ndf['cleaned_genres'] + ' ' + ndf['Author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "tf = TfidfVectorizer(max_features=5000).fit(ndf['cleaned_combined'])\n",
    "tf_matrix = tf.fit_transform(ndf['cleaned_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>Antigone; Oedipus the King; Electra</td>\n",
       "      <td>Sophocles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>Lover Avenged (Black Dagger Brotherhood, #7)</td>\n",
       "      <td>J.R. Ward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>The Known World</td>\n",
       "      <td>Edward P. Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Treasure Island</td>\n",
       "      <td>Robert Louis Stevenson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>The Master of Go</td>\n",
       "      <td>Yasunari Kawabata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>We Disappear</td>\n",
       "      <td>Scott Heim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8862</th>\n",
       "      <td>Tree Oracle - The True Story of Carmen Sylvia</td>\n",
       "      <td>Laural Virtues Wauters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>Easy Money Management: A Give and Save 3-6-5 A...</td>\n",
       "      <td>Laurick Ingram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>All the Light We Cannot See</td>\n",
       "      <td>Anthony Doerr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>The Book of Revelation</td>\n",
       "      <td>Rupert Thomson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Book  \\\n",
       "1201                Antigone; Oedipus the King; Electra   \n",
       "7217       Lover Avenged (Black Dagger Brotherhood, #7)   \n",
       "3473                                    The Known World   \n",
       "294                                     Treasure Island   \n",
       "5625                                   The Master of Go   \n",
       "2151                                       We Disappear   \n",
       "8862      Tree Oracle - The True Story of Carmen Sylvia   \n",
       "5913  Easy Money Management: A Give and Save 3-6-5 A...   \n",
       "6517                        All the Light We Cannot See   \n",
       "8010                             The Book of Revelation   \n",
       "\n",
       "                      Author  \n",
       "1201               Sophocles  \n",
       "7217               J.R. Ward  \n",
       "3473         Edward P. Jones  \n",
       "294   Robert Louis Stevenson  \n",
       "5625       Yasunari Kawabata  \n",
       "2151              Scott Heim  \n",
       "8862  Laural Virtues Wauters  \n",
       "5913          Laurick Ingram  \n",
       "6517           Anthony Doerr  \n",
       "8010          Rupert Thomson  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(tf_matrix, tf_matrix)\n",
    "indices = pd.Series(ndf.index, index=ndf['Book']).drop_duplicates()\n",
    "\n",
    "def recommend_books(title, top_n = 5):\n",
    "    idx = indices[title]\n",
    "    sim = list(enumerate(cosine_sim[idx]))\n",
    "    sim = sorted(sim, key=lambda x: x[1],reverse=True)\n",
    "    sim = sim[1:top_n+1]\n",
    "    books_idx = [i[0] for i in sim if i[0] != idx]\n",
    "    return df[['Book', 'Author']].iloc[books_idx]\n",
    "\n",
    "#recommend_books(\"The Brothers Karamazov\", 10)\n",
    "recommend_books(\"Dr. Jekyll and Mr. Hyde\", 10)\n",
    "#recommend_books(\"Ubik\", 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
